{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"0\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://ictd2016.files.wordpress.com/2016/04/microsoft-research-logo-copy.jpg\" style=\"width 30px;\" />\n",
    "             </td>\n",
    "        <td>\n",
    "            <img src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/MSR-ALICE-HeaderGraphic-1920x720_1-800x550.jpg\" style=\"width 100px;\"/></td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep IV: Use Case and Examples\n",
    "\n",
    "Deep IV uses deep neural networks in a two-stage instrumental variable (IV) estimation of causal effects, as described in [this ICML publication](http://proceedings.mlr.press/v70/hartford17a/hartford17a.pdf) or in the `econml` [specification](https://econml.azurewebsites.net/spec/estimation/iv.html#deep-instrumental-variables).  In the EconML SDK, we have implemented Deep IV estimation on top of the Keras framework for building and training neural networks.  In this notebook, we'll demonstrate how to use the SDK to apply Deep IV to synthetic data.\n",
    "\n",
    "### Data\n",
    "\n",
    "Deep IV works in settings where we have several different types of observations:\n",
    "* Covariates, which we will denote with `X`\n",
    "* Instruments, which we will denote with `Z`\n",
    "* Treatments, which we will denote with `T`\n",
    "* Responses, which we will denote with `Y`\n",
    "\n",
    "The main requirement is that `Z` is a set of valid instruments; in particular `Z` should affect the responses `Y` only through the treatments `T`.  We assume that `Y` is an arbitrary function of `T` and `X`, plus an additive error term, and that `T` is an arbitrary function of `Z` and `X`.  Deep IV then allows us to estimate `Y` given `T` and `X`.\n",
    "\n",
    "### Estimation\n",
    "\n",
    "To do this, the Deep IV estimator uses a two-stage approach that involves solving two subproblems:\n",
    "1. It estimates the *distribution* of the treatment `T` given `Z` and `X`, using a mixture density network.\n",
    "2. It estimates the dependence of the response `Y` on `T` and `X`.\n",
    "\n",
    "Both of these estimates are performed using neural networks.  See the paper for a more complete description of the setup and estimation approach.\n",
    "\n",
    "### Using the SDK\n",
    "\n",
    "In the `econml` package, our Deep IV estimator is built on top of the Keras framework; we support either the Tensorflow or the Theano backends.  There are three steps to using the `DeepIVEstimator`:\n",
    "\n",
    "1. Construct an instance.  \n",
    "    * The `m` and `h` arguments to the initializer specify deep neural network models for estimating `T` and `Y` as described above.  They are each *functions* that take two Keras inputs and return a Keras model (the inputs are `z` and `x` in the case of `m` and the output's shape should match `t`'s; the inputs are `t` and `x` in the case of `h` and the output's shape should match `y`'s).  Note that the `h` function will be called multiple times, but should reuse the same weights - see below for a concrete example of how to achieve this using the Keras API.\n",
    "    * The `n_samples`, `use_upper_bound_loss`, and `n_gradient_samples` arguments together determine how the loss for the response model will be computed.\n",
    "        * If `use_upper_bound_loss` is `False` and `n_gradient_samples` is zero, then `n_samples` samples will be averaged to approximate the response - this will provide an unbiased estimate of the correct loss only in the limit as the number of samples goes to infinity.\n",
    "        * If `use_upper_bound_loss` is `False` and `n_gradient_samples` is nonzero, then we will average `n_samples` samples to approximate the response a first time and average `n_gradient_samples` samples to approximate it a second time - combining these allows us to provide an unbiased estimate of the true loss.\n",
    "        * If `use_upper_bound_loss` is `True`, then `n_gradient_samples` must be `0`; `n_samples` samples will be used to get an unbiased estimate of an upper bound of the true loss - this is equivalent to adding a regularization term penalizing the variance of the response model (see the `econml` specification linked above for a derivation of this fact).\n",
    "2. Call `fit` with training samples of `Y`, `T`, `X`, and `Z`; this will train both sub-models.\n",
    "3. Call `effect` or `predict` depending on what output you want.  `effect` calculates the difference in outcomes based on the features and two different treatments, while `predict` predicts the outcome based on a single treatment.\n",
    "\n",
    "The remainder of this notebook will walk through a concete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from econml.deepiv import DeepIVEstimator\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "To demonstrate the Deep IV approach, we'll construct a syntetic dataset obeying the requirements set out above.  In this case, we'll take `X`, `Z`, `T`, and `Y` to come from the following distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5000\n",
    "\n",
    "x = np.random.uniform(low=0.0, high=10.0, size=(n,1))\n",
    "theta = np.random.uniform(low=0.0, high=2 * np.pi, size=(n,1))\n",
    "z = x * np.cos(theta) + np.random.normal(size=(n,1))\n",
    "t = x * np.sin(theta) + np.random.normal(size=(n,1))\n",
    "y = t * t - x * x + np.random.normal(size=(n,1))\n",
    "\n",
    "plt.scatter(z[x < 1], t[x < 1], label='low X')\n",
    "plt.scatter(z[(x > 4.5) * (x < 5.5)], t[(x > 4.5) * (x < 5.5)], label='moderate X')\n",
    "plt.scatter(z[x > 9], t[x > 9], label='high X')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll imagine that `Z` and `X` are causally affecting `T`; as you can see in the plot above, low or high values of `Z` drive moderate values of `T` and moderate values of `Z` cause `T` to have a bi-modal distribution when `X` is high, but a unimodal distribution centered on 0 when `X` is low.  `Y` is a non-linear function of `T` and `X` with no direct dependence on `Z` plus additive noise (as required).  We want to estimate the effect of particular `T` and `X` values on `Y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network models\n",
    "\n",
    "Now we'll define simple treatment and response models using the Keras `Sequential` model built up of a series of layers.  Each model with have an `input_shape` of 2 (to match the sums of the dimensions of `X` plus `Z` in the treatment case and `T` plus `X` in the response case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_model = keras.Sequential([keras.layers.Dense(1000, activation='relu', input_shape=(2,)),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(1000, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17)])\n",
    "\n",
    "response_model = keras.Sequential([keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(64, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(32, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(1)])\n",
    "\n",
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.1,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll instantiate the `DeepIVEstimator` class using these models.  Defining the response model *outside* of the lambda passed into constructor is important, because (depending on the settings for the loss) it can be used multiple times in the second stage and we want the same weights to be used every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepIvEst = DeepIVEstimator(n_components = 10, # number of gaussians in our mixture density network\n",
    "                            m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "                            h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "                            n_samples = 50, # number of samples to use to estimate the response\n",
    "                            use_upper_bound_loss = True, # whether to use an approximation to the true loss\n",
    "                            n_gradient_samples = 0, # number of samples to use in second estimate of the response (to make loss estimate unbiased)\n",
    "                            optimizer = 'adam', # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "                            first_stage_options = keras_fit_options, # number of epochs to train treatment model\n",
    "                            second_stage_options = keras_fit_options) # number of epochs to train response model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and predicting using the model\n",
    "Now we can fit our model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.6800 - val_loss: 1.5615\n",
      "Epoch 2/30\n",
      "4500/4500 [==============================] - 4s 870us/step - loss: 1.3631 - val_loss: 1.3460\n",
      "Epoch 3/30\n",
      "4500/4500 [==============================] - 4s 874us/step - loss: 1.3241 - val_loss: 1.3215\n",
      "Epoch 4/30\n",
      "4500/4500 [==============================] - 4s 902us/step - loss: 1.3156 - val_loss: 1.3272\n",
      "Epoch 5/30\n",
      "4500/4500 [==============================] - 4s 863us/step - loss: 1.3159 - val_loss: 1.3222\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "In Lambda, `output_shape` must be a list, a tuple, or a function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-875f9fe487a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeepIvEst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kebatt\\source\\repos\\projectalicecore\\econml\\deepiv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, Y, T, X, Z)\u001b[0m\n\u001b[0;32m    334\u001b[0m                                                                    n)([pi, mu, sig])]),\n\u001b[0;32m    335\u001b[0m                                  \u001b[0md_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                                  self._n_samples, self._use_upper_bound_loss, self._n_gradient_samples)\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kebatt\\source\\repos\\projectalicecore\\econml\\deepiv.py\u001b[0m in \u001b[0;36mresponse_loss_model\u001b[1;34m(h, p, d_z, d_x, d_y, samples, use_upper_bound, gradient_samples)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmake_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0muse_upper_bound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, function, output_shape, mask, arguments, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m                 raise TypeError('In Lambda, `output_shape` '\n\u001b[0m\u001b[0;32m    640\u001b[0m                                 'must be a list, a tuple, or a function.')\n\u001b[0;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: In Lambda, `output_shape` must be a list, a tuple, or a function."
     ]
    }
   ],
   "source": [
    "deepIvEst.fit(Y=y,T=t,X=x,Z=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create a new set of data and see whether our predicted effect matches the true effect `T*T-X*X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJztvXt4VNW9//9aIYQUCFLDLQgYlAjhEtACHr4Yjik3LQjlPGqpoBTEKOiRpEcOUQ8cHno8zWlBikpFKgj+RKmogIJFQEBBKDeliFBEMGgggIBEAhJIZv3+mAuTZO/JzGRm9p6Zz+t58szMmj17r8zsvd57fW5Laa0RBEEQ4pcEqzsgCIIgWIsIgSAIQpwjQiAIghDniBAIgiDEOSIEgiAIcY4IgSAIQpwjQiAIghDniBAIgiDEOSIEgiAIcU6i1R3wh2bNmun09HSruyEIghBV7N69+7TWunlt20WFEKSnp7Nr1y6ruyEIghBVKKWO+rOdmIYEQRDiHBECQRCEOEeEQBAEIc4JiY9AKbUQGAqc0lp3dbVdC/wVSAeKgHu11t8rpRQwB/gFcBH4jdb601D0Q4gerly5QnFxMZcuXbK6KwKQnJxMmzZtqF+/vtVdESwgVM7iRcALwKtebQXAh1rrQqVUgev1FOBOIMP1dyvwoutRiCOKi4tJSUkhPT0d572BYBVaa86cOUNxcTHt27e3ujuCBYTENKS1/hg4W615OLDY9Xwx8Euv9le1k78DTZVSaaHohxA9XLp0idTUVBEBG6CUIjU1VWZncUw4fQQttdYlAK7HFq7264BvvbYrdrUJcYaIgH2Q3yK+scJZbHTG1VgvUymVq5TapZTa9d1330WgW4IgCPFJOIXgpNvk43o85WovBtp6bdcGOF79w1rr+Vrrnlrrns2b15oYJwgBce7cOf785z9b3Y2QsGbNGjp27EiHDh0oLCy0ujtCHTiweSPzHx3LrJF3Mf/RsRzYvDEixw2nELwLjHE9HwOs9Gp/QDn5F6DUbUIShEjhSwgqKysj3Jvgqays5NFHH+Vvf/sb+/fv54033mD//v1Wd0sIggObN7J2/gucP/0daM3509+xdv4LERGDkAiBUuoNYBvQUSlVrJR6ECgEBiqlDgEDXa8B3geOAF8BfwEmhqIPQmyz4rNj9C3cQPuC1fQt3MCKz47VaX8FBQUcPnyYHj16MHnyZDZt2kROTg733Xcf3bp1o6ioiK5du3q2nzlzJtOnTwfg8OHD3HHHHfzsZz8jOzubf/7zn1X27XA4yMjIwG3SdDgcdOjQgdOnT5v259lnn2XcuHEAfP7553Tt2pWLFy/W+n/s2LGDDh06cMMNN5CUlMTIkSNZuXJlrZ8T7Mfmpa9Scbm8SlvF5XI2L33V5BOhIyTho1rrX5u81d9gWw08GorjCvHBis+O8eQ7n/PjFeed+rFzP/LkO58D8Mubg4szKCwsZN++fezZsweATZs2sWPHDvbt20f79u0pKioy/Wxubi7z5s0jIyOD7du3M3HiRDZs2OB5PyEhgdGjR7NkyRLy8vJYv3493bt3p1mzZqb7zMvL4/bbb2f58uU888wzvPTSSzRs2JCNGzeSn59fY/uGDRuydetWjh07Rtu2Vy2tbdq0Yfv27UF8I4LVnD9jfKNg1h5KoqLonBDf/PGDgx4RcPPjlUr++MHBoIXAiN69e9caR19WVsbWrVu55557PG3l5eU1ths3bhzDhw8nLy+PhQsXMnbsWJ/7TUhIYNGiRWRlZfHwww/Tt29fAHJycjxiZYTzvqoqEgEUnaSkNnOahQzaw40IgWB7jp/7MaD2YGnUqJHneWJiIg6Hw/PaHWPvcDho2rSpz8EZoG3btrRs2ZINGzawfft2lixZUuvxDx06ROPGjTl+/GrsRG0zgjZt2vDtt1ejsYuLi2ndunWtxxLsR/bIB1g7/4Uq5qHEpAZkj3wg7MeWWkOC7Wnd9CcBtftDSkoK58+fN32/ZcuWnDp1ijNnzlBeXs6qVasAaNKkCe3bt2fZsmWA8478H//4h+E+xo8fz+jRo7n33nupV68eAMuXL+fJJ5+ssW1paSmTJk3i448/5syZM7z11lvA1RlB9b+tW7cC0KtXLw4dOsTXX3/N5cuXWbp0KcOGDQv6exGsIzM7h0G5j5HSrDkoRUqz5gzKfYzM7JywH1tmBILtmTy4YxUfAcBP6tdj8uCOQe8zNTWVvn370rVrV+68806GDBlS5f369eszbdo0br31Vtq3b0+nTp087y1ZsoQJEybwP//zP1y5coWRI0fSvXv3GscYNmwYY8eOrWIWOnz4ME2aNKmxbX5+PhMnTuSmm25iwYIF5OTk0K9fP1q0aFFjW28SExN54YUXGDx4MJWVlYwbN44uXboE+nUINiEzOyciA391lJGN0W707NlTy8I0scWBAwfIzMz0e/sVnx3jjx8c5Pi5H2nd9CdMHtwxpP6BcLBr1y7y8/PZvHmzp2306NHMnj0bO+bGBPqbCPZHKbVba92ztu1kRiBEBb+8+TrbD/zeFBYW8uKLL9bwDbz22msW9UiwEwc2b2Tz0lc5f+Y0KanNyB75gCUzATfiIxCEMFBQUMDRo0e57bbbrO6KYDOsTBwzQ4RAEAQhgliZOGaGCIEgCEIEsTJxzAwRAkEQhAhiliAWicQxM0QIBEEQIkj2yAdITGpQpS1SiWNmiBAIQoho3Lixpcc/e/YsAwcOJCMjg4EDB/L9999b2h/BGCsTx8yQ8FFB8EFlZaUnK9juFBYW0r9/fwoKCigsLKSwsJD/+7//s7pbggFWJY6ZITMCITrY+ybM7grTmzof975Zp90VFRXRqVMnxowZQ1ZWFnfffben7HN6ejozZszgtttuY9myZaZlp7/++mv69OlDr169mDp1quFxpk6dypw5czyvn376aZ577jnTfh09epSMjAxOnz6Nw+EgOzubtWvX+vU/rVy5kjFjnEuAjBkzhhUrVvj1OUEQIRDsz9434b3HofRbQDsf33u8zmJw8OBBcnNz2bt3L02aNKmyUE1ycjJbtmxh5MiR5Obm8vzzz7N7925mzpzJxInOJTQmTZrEhAkT2LlzJ61atTI8xoMPPsjixYsBZ8G6pUuXMmrUKNM+XX/99UyZMoVHHnmEWbNm0blzZwYNGgRAdnY2PXr0qPG3fv16AE6ePElaWhoAaWlpnDp1yvQ4guCNmIYE+/PhDLhSrdLolR+d7Vn3Br3btm3beso9jx49mueee44nnngCgF/96leA77LTn3zyCW+//TYA999/P1OmTKlxjPT0dFJTU/nss884efIkN998M6mpqT77NX78eJYtW8a8efOqVDn1LlUhRAd2yyA2I6xCoJTqCPzVq+kGYBrQFHgIcBfffkpr/X44+yJEMaXFgbX7SfW6/d6v3SWpays77U/t//Hjx7No0SJOnDjhWYXMFxcvXqS42Pm/lZWVkZKSAjhnBEYVU2fOnMmAAQNo2bIlJSUlpKWlUVJSUmvBOiG8uDOI3clj7gxiwHZiEFbTkNb6oNa6h9a6B/Az4CKw3PX2bPd7IgKCT65pE1i7n3zzzTds27YNgDfeeMOwHISvstN9+/Zl6dKlAD7XGxgxYgRr1qxh586dDB482NPuXdHUmylTpjBq1ChmzJjBQw895GnfvHmzYUnqAQMGAM5qp24z1OLFixk+fLjf34UQeuyYQWxGJH0E/YHDWuujETymEAv0nwb1q609UP8nzvY6kJmZyeLFi8nKyuLs2bNMmDDBcLslS5awYMECunfvTpcuXTxrAs+ZM4e5c+fSq1cvSktLTY+TlJRETk5OlXUJTp8+bbi62EcffcTOnTs9YpCUlMQrr7zi1/9TUFDAunXryMjIYN26dRQUFPj1OSE82DGD2IyIlaFWSi0EPtVav6CUmg78BvgB2AX8h9b6+2rb5wK5AO3atfvZ0aOiH7FEwCWP977p9AmUFjtnAv2n1ck/UFRUxNChQ9m3b1/Q+/AXh8PBLbfcwrJly8jIyABg1apVHDlyhMcffzzsx/cXKUMdWuY/OtZ46clmzcmd65+41xV/y1BHZEaglEoChgHLXE0vAjcCPYASYFb1z2it52ute2qte9qxdrsQYbLuhfx9MP2c87EOIhBJ9u/fT4cOHejfv79HBACGDh1qKxEQQo8dM4jNiFTU0J04ZwMnAdyPAEqpvwCrItQPQQCc0TyRmA107tyZI0eOhP04gv1wO4TjPmrIi18Db7hfKKXStNYlrpcjgPBfkYIgCBHGbhnEZoRdCJRSDYGBwMNezX9QSvUANFBU7T1BEAQhgoRdCLTWF4HUam33h/u4giAIgn9IZrEgCEIdiZYMYjOk1pAQl5w7d65KbaFoJj09nW7dutGjRw969qw1UlAIMXZcgzhQRAiEuMSXEFRWVka4N3Vn48aN7Nmzh127dlndlbgjmjKIzRAhEKKC1UdWM+itQWQtzmLQW4NYfWR1nfZXUFDA4cOH6dGjB5MnT2bTpk3k5ORw33330a1bN4qKiujatatn+5kzZzJ9+nQA07LUbhwOBxkZGXz33Xee1x06dOD0afOM0meffdZTh+jzzz+na9eunrLYgr2JpgxiM8RHINie1UdWM33rdC5VXgKg5EIJ07dOB2DIDUOC2mdhYSH79u3zFJPbtGkTO3bsYN++fbRv356ioiLTz+bm5jJv3jwyMjLYvn07EydOZMOGDZ73ExISGD16NEuWLCEvL4/169fTvXt3mjUzX5M2Ly+P22+/neXLl/PMM8/w0ksv0bBhQzZu3Eh+fn6N7Rs2bMjWrVsBZ+G7QYMGoZTi4YcfJjc3N6jvRAiOlNRmxhnEFq5BHCgiBILtmfPpHI8IuLlUeYk5n84JWgiM6N27N+3bt/e5ja+y1N6MGzeO4cOHk5eXx8KFCxk7dqzP/SYkJLBo0SKysrJ4+OGHPeWxc3JyTCufuvnkk09o3bo1p06dYuDAgXTq1Il+/fr5/IwQOrJHPlClyijYN4PYDBECwfacuHAioPZgcZeeBkhMTMThcHheX7rkFKLaylK7adu2LS1btmTDhg1s377dZ3VSN4cOHaJx48YcP37c0+bPjKB169YAtGjRghEjRrBjxw4RgggSTRnEZogQCLanVaNWlFwoMWwPlpSUFMPa/m5atmzJqVOnOHPmDI0bN2bVqlXccccdVcpS33PPPWit2bt3L927d6+xj/HjxzN69Gjuv/9+T9XR5cuXs2PHDn7/+99X2ba0tJRJkybx8ccf89hjj/HWW29x99131zojuHDhAg6Hg5SUFC5cuMDatWuZNq1uVVmFwImWDGIzxFks2J5Jt0wiuV5ylbbkeslMumVS0PtMTU2lb9++dO3alcmTJ9d4v379+kybNo1bb72VoUOHVlk7wKwsdXWGDRtGWVlZFbPQ4cOHadKkSY1t8/PzmThxIjfddBMLFiygoKDAr6UmT548yW233Ub37t3p3bs3Q4YM4Y477vDnKxAEDxErQ10XevbsqSUsLrYItOTx6iOrmfPpHE5cOEGrRq2YdMukkPoHwsGuXbvIz8+vssTk6NGjmT17NnasqCtlqGMPf8tQi2lIiAqG3DDE9gO/N4WFhbz44os1fAOvvfaaRT0SQkG0ZxCbIaYhQQgDBQUFHD161HD5SyE6iYUMYjNECARBEPwgFjKIzRAhEARB8INYyCA2Q4RAEATLKH3vPQ79vD8HMjtz6Of9KX3vPau7ZIpZpnA0ZRCbEXYhUEoVKaU+V0rtUUrtcrVdq5Rap5Q65Hr8abj7IQiCvSh97z1Kpk6j4vhx0JqK48cpmTrNtmIQTWsQB0qkZgQ5WuseXmFMBcCHWusM4EPXa0GIaho3bmzp8adPn851111Hjx496NGjB++//76l/amNU7P/hL5UtXSIvnSJU7P/ZFGPfJOZncOg3MdIadYclCKlWXMG5T4WE1FDVoWPDgdudz1fDGwCpljUF0EwpbKy0pMVHA3k5+fzxBNPWN0Nv6goqZkt7qvdDkR7BrEZkZgRaGCtUmq3UspdFrGle/F612OLCPRDiGJCbUsuKiqiU6dOjBkzhqysLO6++25P2ef09HRmzJjBbbfdxrJly0zLTn/99df06dOHXr16MXXqVMPjTJ06lTlz5nheP/300zz33HOm/Tp69CgZGRmcPn0ah8NBdnY2a9eurdP/ajfcvyUmyayJaWkR7pEQCSHoq7W+BbgTeFQp5Vc1LKVUrlJql1Jql7uuuxCfhMuWfPDgQXJzc9m7dy9NmjSpslBNcnIyW7ZsYeTIkeTm5vL888+ze/duZs6cycSJEwGYNGkSEyZMYOfOnbRqZVz36MEHH2Tx4sWAs2Dd0qVLGTVqlGmfrr/+eqZMmcIjjzzCrFmz6Ny5M4MGDQIgOzvbY/bx/lu/fr3n8y+88AJZWVmMGzeO77//vk7fTzio8lsaoJKTaZGfF+Fe1eTA5o3Mf3Qss0bexfxHx8ZEroAvIlpiQik1HSgDHgJu11qXKKXSgE1a645mn5MSE7FHIOUMDv28v+HAkdi6NRkbPgzq+EVFRfTr149vvvkGgA0bNvDcc8+xYsUK0tPT+eijj7j++uspKyujefPmdOx49fQsLy/nwIEDpKamcuLECerXr88PP/xA69atKSsrq3GsgQMH8oc//IGTJ0/y8ssv89Zbb9Xav8GDB/PVV1+xZ88eUlJS/PqfTp48SbNmzVBKMXXqVEpKSli4cKGf30hkSkyY/Zbg/D1b5OdxzV13hbUPteFOHKteVjoa/QG2KDGhlGoEJGitz7ueDwJmAO8CY4BC16Nx1S5BIHy2ZKWU6Wt3Serayk5X34cR48ePZ9GiRZw4ccKzCpkvLl68SHFxMeBc/8AtBNnZ2YYVU2fOnMmAAQNo2bKlp+2hhx5i6NChtR4r0pj+ZkoFLeqhxlfiWLQJgb+E2zTUEtiilPoHsANYrbVeg1MABiqlDgEDXa8FwRAzm3FdbcnffPMN27ZtA+CNN94wLAfhXXYaQGvNP/7xDwD69u3L0qVLAXyuNzBixAjWrFnDzp07GTx4sKfdu6KpN1OmTGHUqFHMmDGDhx56yNO+efNm9uzZU+NvwIABAJR4DbLLly+vstSmXQjXbxlKYjlxzIywCoHW+ojWurvrr4vW+hlX+xmtdX+tdYbr8Ww4+yFENy3y81DJVctQh8KWnJmZyeLFi8nKyuLs2bNMmDDBcDuzstNz5sxh7ty59OrVi9LSUtPjJCUlkZOTw7333uuJQDp9+jRGZtmPPvqInTt3esQgKSmJV155xa//5z//8z/p1q0bWVlZbNy4kdmzZ/v1uUjgdhBXHD8O1WdiNvELuInlxDEzpAy1YAmB2qNL33uPU7P/REVJCYlpaXW2JRcVFTF06FD27dsX9D78xeFwcMstt7Bs2TIyMjIAWLVqFUeOHOHxxx8P+/H9JVw+AreDuHrOANjHL+CN+AgEwaZcc9ddthos/GX//v0MHTqUESNGeEQAsKX9PlwYJY5B3Zz94SQWlp4MFBECIS5JT0+PyGygc+fOHDlyJOzHsTOSOGZ/pOicIAghxzsBkATjYcZODuJ4R2YEgiCElBo+gcrKGtvYzUEc74gQCIIQUsx8AtSrBw5HSJz9QmgRIRAEIaSY2v4dDjIP7I9sZwS/EB+BEJecO3euSm2haGbcuHG0aNGiRgLZ2bNnGThwIBkZGQwcODBitYeiIWnMTbzVFDJDhECIS3wJQaWBTdvO/OY3v2HNmjU12gsLC+nfvz+HDh2if//+FBaGN4E/mpLGILYXow8UEQIhKvhy+wkWP/UJcx/ZwOKnPuHL7SfqtL+CggIOHz5Mjx49mDx5Mps2bSInJ4f77ruPbt26UVRUVOUOe+bMmUyfPh3AtCy1G4fDQUZGBu6quQ6Hgw4dOnD6tHmJgmeffdZTh+jzzz+na9eunrLYtdGvXz+uvfbaGu0rV65kzJgxAIwZM4YVK1b4tb9gqFFV1CtRNbF1a9J+N8N2PoFYXow+UMRHINieL7efYOOSf1Jx2QFA2dlyNi5xDr433Wpc/rk2CgsL2bdvn6eY3KZNm9ixYwf79u2jffv2FBUVmX42NzeXefPmkZGRwfbt25k4cSIbNmzwvJ+QkMDo0aNZsmQJeXl5rF+/nu7du9OsmXmJgry8PG6//XaWL1/OM888w0svvUTDhg3ZuHEj+fn5NbZv2LAhW7du9fk/njx5kjSXOSYtLY1Tp0753L4uRFvSGMRnTSEzRAgE27Nt5WGPCLipuOxg28rDQQuBEb1796Z9+/Y+tykrK2Pr1q3cc889nrby8vIa240bN47hw4eTl5fHwoULGTt2rM/9JiQksGjRIrKysnj44Yfp27cvADk5OaaVT+1ENCaNpaQ2c5qFDNrjDRECwfaUna050PpqDxZ36WmAxMREHI6r4nPJdbdbW1lqN23btqVly5Zs2LCB7du3+6xO6ubQoUM0btyY4171+usyI2jZsiUlJSWkpaVRUlJCixbhWwgwMS3NeM0IGzqI3WSPfMCwplAsLEYfKOIjEGxP42sbBNTuDykpKYa1/d20bNmSU6dOcebMGcrLy1m1ahXguyx1dcaPH8/o0aOrVB1dvnw5Tz75ZI1tS0tLmTRpEh9//DFnzpzxLF7jnhFU/6tNBACGDRvmWR1t8eLFDB8+vNbPBEq0OYi9ieXF6ANFhECwPX2G30hiUtVTNTEpgT7Dbwx6n6mpqfTt25euXbsyefLkGu/Xr1+fadOmceuttzJ06NAqaweYlaWuzrBhwygrK6tiFjp8+DBNmjSpsW1+fj4TJ07kpptuYsGCBRQUFPht0//1r39Nnz59OHjwIG3atGHBggWA0yG+bt06MjIyWLduHQUFBX7tz1+i0UFcnczsHHLnvsJ/LH2P3LmvxKUIgJShFiwi0JLHX24/wbaVhyk7W07jaxvQZ/iNIfUPhINdu3aRn5/P5s2bPW2jR49m9uzZNG/e3MKeGRPobxKOJUSF0GJ5GWqlVFvgVaAV4ADma63nuNYtfghwe2me0lq/H65+CLHBTbe2sv3A701hYSEvvvhiDd/Aa6+9ZlGPQk80OogFY8JpGqoA/kNrnQn8C/CoUqqz673ZWuserj8RASHmKCgo4OjRo4bLX8YK0ZRBLPgmbEKgtS7RWn/qen4eOABcF67jCYIQfrzLS1devIiqX7/K+3Z3EAvGRMRZrJRKB24GtruaHlNK7VVKLVRK/TQSfRAEoW5UcQ5rjT53Dq019Zo2BaWixkEs1CTseQRKqcbA20Ce1voHpdSLwO8A7XqcBYwz+FwukAvQrl27cHdTEIRaMMwerqhANWxI5t+3WdMpPziweWNcLTsZDGEVAqVUfZwisERr/Q6A1vqk1/t/AVYZfVZrPR+YD86oobr2JRqjTgTBTkSjc7j6QvTuwnKALcXAqnEqbKYhpZQCFgAHtNbPerV7e5JGAGFfONZdq8adiequVVPXwmWC4E3jxo0tPf6yZcvo0qULCQkJVA+3/v3vf0+HDh3o2LEjH3zwQVD7j0bncDQVlrNynAqnj6AvcD/wc6XUHtffL4A/KKU+V0rtBXKAmvnzIcZXrRpB8EU0laTu2rUr77zzDv369avSvn//fpYuXcoXX3zBmjVrmDhxYkD/VzRnD0dTYTkrx6lwRg1t0VorrXWWd6io1vp+rXU3V/swrXXY55WRqlUjhI9QLyBSVFREp06dGDNmDFlZWdx9992ess/p6enMmDGD2267jWXLlpmWnf7666/p06cPvXr1YurUqYbHmTp1KnPmzPG8fvrpp3nuuedM+3X06FEyMjI4ffo0DoeD7Oxs1q5d69f/lJmZSceOHWu0r1y5kpEjR9KgQQPat29Phw4d2LFjh1/7jPbsYbMCcnYsLGflOBUXJSbCUatGiBzhWkDk4MGD5ObmsnfvXpo0aVJloZrk5GS2bNnCyJEjyc3N5fnnn2f37t3MnDmTiRMnAjBp0iQmTJjAzp07adXK2I774IMPeur9OBwOli5dyqhRo0z7dP311zNlyhQeeeQRZs2aRefOnRk0aBAA2dnZ9OjRo8bf+vXrff6fx44do23btp7Xbdq04dixY359R7WVl7azCICzsFxiUtXr3K6F5awcp+Ki+mif4TdWqWcPda9VI0QOX3beujj82rZt6yn3PHr0aJ577jmeeOIJAH71q18BvstOf/LJJ7z99tsA3H///UyZMqXGMdLT00lNTeWzzz7j5MmT3HzzzaSmpvrs1/jx41m2bBnz5s2rUuXUu1RFIBiVkVHVTDxmRKOD2Bv3+RENUUNWjlNxIQRur7tEDUUn4bLzVh8MvV+7S1LXVnbanwF1/PjxLFq0iBMnTnhWIfPFxYsXKS4uBpxClJKSAjhnBEYVU2fOnMmAAQNM99emTRu+/fZbz+vi4mJat25daz8gOstLVyczO8eWA391rByn4kIIIPpq1QhXCdcCIt988w3btm2jT58+vPHGG4blILzLTt9zzz1ordm7dy/du3enb9++LF261LMamRkjRoxg2rRpXLlyhddff93T3qlTpxrLXAJMmTKFUaNGcf311/PQQw95SmAHOyMYNmwY9913H7/97W85fvw4hw4donfv3n59tkV+HiVTp1UxD9ndQRzNWDVOxYWPQIhuwmXnzczMZPHixWRlZXH27FkmTJhguJ1Z2ek5c+Ywd+5cevXqRWlpqelxkpKSyMnJqbIuwenTpw1NNh999BE7d+70iEFSUhKvvPKKX//P8uXLadOmDdu2bWPIkCEMHjwYgC5dunDvvffSuXNn7rjjDubOnevphxnuSKHj/zkFkpMlezjGifsy1JJoZg2BljwOdXZoUVERQ4cOZd++sKex4HA4uOWWW1i2bBkZGRkArFq1iiNHjvD444+H/fj+4v5N3JFC1WcBIgChI1LjjuVlqKOBcCyKHg2sPrKaOZ/O4cSFE7Rq1IpJt0xiyA1DrO6WT6LFzlud/fv3M3ToUEaMGOERAYChQ4da2CvfGEUK6UuXODX7TyEXgmg8F+uKHceduBaCSC2KbidWH1nN9K3TuVTpvNBLLpQwfet0gJi/AL1JT0+PyGygc+dE1A2hAAAbkElEQVTOHDlyJOzHCSWRihSK13PRjuNOXPsI4jHRbM6nczwXnptLlZeY8+kck0+Ej2gwS8YL3r9FpEpJ2OlcjCR2HHfiWgjiMdHsxAXjuiUlF0rIWpzFoLcGsfrI6rD3Izk5mTNnzogY2ACtNae++YbKzz6LyDoDq4+sZtBbgyi5YDzDMDtHayPU2efhwo7jTlybhuIx0axVo1amF6BGR2x63qZNG4qLi/nuu5phoUJkcVy8iOPzfdT785896wyQmEi9pk2pLC0lMS2NFvl5IfEPVDcHGdGqUeDmkWiqMmrHcUeihuIsasifC9FNWqO0uHDexTuRWITe7RQ2uwlxk1wvmen/b3rA59z8R8ca55o0a07uXP/CbyOJRA3ZjHhLNHNfYO5IDY35jUC8OO/inXA7h/29+ajLjUc0VRkF+407ce0jiFeG3DCEtXevZe+YvaQ18u0AjAfnXbwTbuewkVO4OmmN0lh799qgbziiqcqoHREhiHMm3TKJ5HrJPrcpuVASMSeyEHla5OehkqueA3V1DrsdwlmLs/wyB026ZVLQx4LoqjJqR+LeNGRGvPgOvE1Fvi5YMRPVkVW/hV0LqjUq6DkOhj5r+JFI4XYCn5r9JypKSursHLbCD2XXKqPRMo5Y5ixWSt0BzAHqAS9rrQvNtg2ns9iI6pl/4PTq54zqZMsfMVT4cwEnqAS01jGVBbris2M8+c5efrziqH1j4KcN6/Pfd3XhlzdfV+O9ne++RObuqTSiZky4UaFSDaieD1oiBqXvvReywR/8dwhD8E7haMIO44itncVKqXrAXGAgUAzsVEq9q7Xeb0V/qmPHzL9I4M/swKGd30uszBBWfHaM3/51D/5JgJPvL14h7697KH37ce6vtx7v8b0nxgO+GQqo3PUK9SIsBNXrCVUcP07J1GkAQYmBv7MAhYqpmwhfRNM4YpVpqDfwldb6CIBSaikwHLCFENgx8y9SDLlhCENuGOIz4ceN25EczRf0Hz84yNCELTyTuIDGKvDfN5BB34wEHYgMhYZQ1xMKxCEcL0TTOGKVs/g64Fuv18WuNltgx8y/SOOPExmi35Hc84d1zKr/IikJ5ShFwH+hoNKCyzBUIaO1ZQm7CYVDONqIpnHEKiEwuoSqOCuUUrlKqV1KqV2Rzj7tM/xGEpOqfjVWZ/5FmiE3DGH6/5tOWqM0FIoEZX6quM1E0SgGTyYto76yLqlSa3i9sn/EjxuKkFG3Oag2EUhrlBbz/gAjomkcsco0VAy09XrdBqiS2qi1ng/MB6ezOHJdk6Ut3bjNRFC7DfhS5SUKNhcw59M5UWX/bUnkE47c8Rka+P8qB3Co539H7NgeB/Hx484pjVewiD8ho95lo5VSHp+REfHgEPZFNI0jVgnBTiBDKdUeOAaMBO6zqC+G2C3zz2piNcxUXdMGSr+tfcMgqR6U50DxWmV//rtiHAoY9S/t+J9fdgvb8b2pseCMd8XR1q1rjRqqfjPgK+JQypM4iZZxxMrw0V8Af8IZPrpQa/2M2baRDh/1RbTEBYcTf2zCURNmuvdNeOdhCChuqCZGl9E5lcJXt0yl17CH67TvUBFsTaFAwkIh/pzCYN9xwdbhowBa6/eB9606fjDYcWUhK5h0y6RaQwWjJsw0617n43t5cOVCcPtIaoQa+qer+3LxU6BX3XpXZ7xzBQzVCt8O4kCSwyA+ncKxMC5IZnEARFNccDjx10zkxvb+g6x7awzisYDR2sNGGDmIA5kFRHr2F+r1q+tKLIwLIgQBEE1xweHG7UgO5I7R9rODGMMoV6A6Rg7iQH7TSDuE7bjuQCyMC1J0LgCiKS44UgQSZgpXZwfRnHtgd0rfe8/UH+BBKRJbtybtdzO45q67qhSJe2rLU37XCYp0VNDmpa96RMBNxeVyNi99NWJ9qE4sjAsyIwgAO64sZAcCCTN1I7OD8OCPOai6cziQaCCwNizUjusOxMK4IEIQANEUF2wVgfgPLlVe4qktT/Hk5iftH11kc6rkB/jA2xQUaDQQWB8WmpLazHglMgvXHYiFcSHul6oUwkcwESfxnIAULH47hb1yBaL1t6nuIwDnugODch+zvOS0HfE3fFSEQAgr0XjXGQ1UCQtNSIDKSp/bu81Bdo4G8he7RQ3ZGRGCCGPXhBK7EOgdqBsRhZr4OwNwc7m+Yt6dis9v/ikXKy5yxXGl1s/YZQZgN6LtOrd9QlksEQsJJeHG23fgT50aN+JUvoq/fgA3GjhzjWLJv8InXRLgcqlfnxPxNSaWr3OZEYSAxU99Yhgz3PjaBoz5374W9Mj+BDpDsKuZIlIEMwt48U74pEs9v48hswDfRON1LjOCCBILCSWRJtDsZO+SFQWbCyjYXBAXd66BzAIqFSgNZ5rA67cHJgLx8F3WlVi+zkUIQkDjaxuY3ikI5gSTnexNrItCILOA8kSY9wsV0OAPMgsIhFi+ziWzOARE0wIUdsQ7OzlYSi6U8F9b/ovspdlkLc6K2sxld1bwgczOHC94slYR0MB3TfwXgUSVSNMGTVGouF0wJlhi+ToXH0GIiLZoAjsTyOIn/hAts4VA/QCXEuGlAGYB0fI92Jlou84lfFQwxTsGPTEtjcb/2o+yjz6moqQEdc01JACVpaVVnodiu8S0tFoXP6lOsGYjM+w4GAYTDXS6Cbx+u38iIOaf+EWEwCbY7Q4i0LvOcJHYurXfghFMUprPY6tEGic1prS8lCZJTVBKUVpeGtGIpE0LZlB//ps0La1EYbyItxEyC4gMdrtug8VSIVBK/RG4C7gMHAbGaq3PKaXSgQPAQdemf9daP1Lb/qJVCKrHHYPTppgzqpNlJ1WtVSltRnXBqGiczKXKchpedFCWDCho/KM7UiZwZ6kZaY3S6NemHx8Xf8yJCyeqCEZ18TDbbsDBJP7twx/5aamDsp+AQtHoR03ZT+Anl6G+72RgD1WjgYz/R29xi9cQ21Bhx+s2WKwWgkHABq11hVLq/wC01lNcQrBKa901kP1FqxDYMe74QGZn05Wqop0rCn5MdgqDt0iEUzCq0/eLSu7bpEn9gYDu9M3wZwYQq3f9VpWSsON1GyyW5hForb0XLP07cHc4jmN37Bh3nJiWFlUzgkCor6H+j87nTbwsX97Pm/8AE97TjF1XEbRIeA/2Z5rArg7Q8ytCNvhD7X6AWB383Vi5AI0dr9twE4k8gnHAX71et1dKfQb8APyX1nqz0YeUUrlALkC7du3C3slwYMe44xb5ebbwEVhJkoYkA8Fo/gP8+7uax9+t4HS1Ad5bMLwH++Y/wB2fhmbwd+M9C0hUiTSNQ5OPrwVowi0Edrxuw03QQqCUWg8YGcye1lqvdG3zNFABLHG9VwK001qfUUr9DFihlOqitf6h+k601vOB+eA0DQXbTyux44IVbgdsxKOGzp0DpWxvlnJHiVcf4Jv40M1QiIDDtR/vWUCs3/X7wsoFaOx43YaboIVAaz3A1/tKqTHAUKC/djkitNblQLnr+W6l1GHgJiD6HAB+YNcFK665666AQjhDhV9hqzYSjFDe5VfnioJLyU7n8dlrEljRvyHrOpZ77vrnxeHg742VC9DY9boNJ+FyFt8BPAv8q9b6O6/25sBZrXWlUuoGYDPQTWt91tf+otVZ7ItYCU8LB8HkOahrroELF9BXai+xHEncV9d5r6ihc9fU40ruvdz+4DRL+2ZnIrUATaxfh1YXnXsBaACsU0rB1TDRfsAMpVQFUAk8UpsIxCKxXM42FAQ7Y/EWEDsIhveKYEJguAf7cEYNyXV4FUkos4BYCk+LRgwFI0iTVPU8h2CypwVriIfr0OoZgeCDeAxPsxNmMw5/TVIy2McGch1eRYTAAuIxPC0asMqJLliDXIdXkTLUFhDL5WwFIVqQ6/AqMiOwgHgMTxMEuyHX4VXEWSwIgqVYVVMoHhBncZQS63HNguBNJGoKyTVVO+IjsBHuuGa3A8sd1/zl9hMW90wQwoOvmkKhQK4p/xAhsBHbVh6uUt8EoOKyg20rD1vUI0EIL+GuKSTXlH+IENgIiWsW4g2z2kGhqikk15R/iBDYCLP45XiMaxbig+yRD5CYVPX8TkxqQPbIB0Kyf7mm/EOEwEZIXLMQb2Rm5zAo9zFSmjUHpUhp1jykheXkmvIPiRqyEb7imiXyQYhVMrNzQjLw+7pG5NrxjQiBzbjp1lY1TlKpkigIvqntGpHrxDciBFGAr8gHOcGFaCGciWNyjdQNEYIoQCIfhGgn3Iljco3UDXEWRwES+SBEO+FOHJNrpG6ETQiUUtOVUseUUntcf7/weu9JpdRXSqmDSqnB4epDrCCRD0K0E+7EMblG6ka4TUOztdYzvRuUUp2BkUAXoDWwXil1k9a6Msx9iVok8kGIdsK9GL1cI3XDCh/BcGCp1roc+Fop9RXQG9hmQV+iBrPIBwkrFaKB7JEPGC5GH0zimNk5L9FBwRNuH8FjSqm9SqmFSqmfutquA7712qbY1VYFpVSuUmqXUmrXd9/VvJMQpKCWED2EKnFMzvnwUKcZgVJqPWAkwU8DLwK/A7TrcRYwDlAG29dYFEFrPR+YD871COrSz1hFQuaEaCIUiWNyzoeHOgmB1nqAP9sppf4CrHK9LAbaer3dBjhel37EKxIyJ8Qbcs6Hh7D5CJRSaVrrEtfLEcA+1/N3gdeVUs/idBZnADvC1Y9YRhbfFuxIOBPH5JwPD+H0EfxBKfW5UmovkAPkA2itvwDeBPYDa4BHJWIoOCRkTrAb7sSx86e/A609iWMHNm8Myf7lnA8PYZsRaK3v9/HeM8Az4Tp2vFBbyJxEFAmRxlfiWDCOYSkiFxnipsRErC6Q7SusVArVCZEmVIljUkQussSFEPiqcwLEpEBIdIVgBaFKHJPzN7LEhRCYTVc/XDSfysuXw1YIy0okukKwglAljsn5G1niQgjMpqXlZedrtHkXwormmYJEVwhW4L5G6nrtyPkbWZTW9s/V6tmzp961a1fQn5//6FjD6aovEpMa1LirGZT7GBAdAlHdxgrO6IqcUZ0AcbYJdSdUfjcjpzBgev7Kueo/SqndWuuetW4XD0JQ3UcAzoE9sUESl87XnBWohAS0w1GjvUHjlCqmJPd+7CoQcoEJ4cLsmgq0bITcsIQXEYJqGN29AIYnc3V/Qm34EgirxaA6i5/6xHTKPeZ/+1rQIyEaMZtlpzRrTu7cV/zej5yP4cVfIYgLHwH4rnNSXSA2L301IFNSNPkaxAknhIJQhYnK+WgP4kYIzDATiEBMSWa4o5DsFJUkTjghFIQqTFTOR3sgS1UaYFYy9+djcklMqnqCJiY1IDklxXA/KiHBNMvywOaNzH90LLNG3sX8R8eGLAW/NiRFXwgF2SMfMLwWAg0TlfPRHsT9jMCMQExJEJivwcqZgq8UfSlJIRjhKzooELOnlIywL3HjLA43RheLma/BLCoppVnzq5+LsE/BV/SGXJTxSySig+T8Ch/iLI4wgfga7DhTkJR+wYhQFZGT88veiBCEEbPps6+ZgtlFZ7SfUIqDRG8IRkh0UHwgQhBmomWm4Ct6Q3wH8Usw0UFG54tEB9mbsAiBUuqvQEfXy6bAOa11D6VUOnAAOOh67+9a60fC0Qc7Y8eZQp/hNxracNO7pko56zjByM8VaBE5s/LRnf6lFf/8+4ka55dEB9mDsDuLlVKzgFKt9QyXEKzSWncNZB/R4CwOBWaOOV+ZzmY1kUJV88X9ujqS+Rlb+HIKg/83G74yhb3PJ5lZRgZbOIuVUgq4F/h5OI8TK4RyppCZnRNwUTCjBT/WvbLfcFux7cYWvpzCuXNf8fvGwpcvQBaUsS/h9hFkAye11oe82torpT4DfgD+S2u9Ocx9iCpC4lM4c9rnYjyBzBbEthsfhMopLOdLdBK0ECil1gNG8v601nql6/mvgTe83isB2mmtzyilfgasUEp10Vr/YLD/XCAXoF27dsF2MyYIdKaQktrM5x2e0b7MxMHMd9Bn+I3iRI5SjGaKoXIK+zpfBPsSNh+BUioROAb8TGtdbLLNJuAJrbVPB0C8+AgCxZdd9/25z4LJbxuoX0HKWccOZudMl3/tzxcffej3eSHlo6MDO/gIBgD/9BYBpVRz4KzWulIpdQOQARwJYx9iGl9p/qGMQDKy7S5+6hNJEIpCzGaKRz7byaDcx/yeKfpKEBvzv33lHIgywikEI6lqFgLoB8xQSlUAlcAjWuuzYexDzGPmUzAL+wsmVwFqCkTZWePZhjiR7YFZoIAvX4Cv+lrVkQSx2CJsQqC1/o1B29vA2+E6pnCVUEUgfbhofpVFd9wCkdx0MBVXOtTYjySgWY+vQAFJEBOMkMziGCYUEUhmi+5U/rgFrSooL9sMjvOQkEKDxtmkd/25JKBFELNih2bmP0kQE4wQIYgzAp0pmPHj+bPUS1wPjsvOBsd5Ki6u55/bErlUdoWKS1s8ApGYfBvbVtYXIQgxZnf+vsKKAy0fbeYLKNp3hpxRnWTmFyOIEMQhoViVTSUkUFlxuUpbZcVlyk59gNP9U+FsdJyn4uI6zpXAl9slszRYArnzNy1z7jL/mP3+RiYgSRCLD0QIBMB8pgCBmZLAqL2CyvJPWPuy8piSLpWmsPblbODfZDCphUDv/LXDYRgi7Gv1MDMTUHKjRC5dqKixvfgCYgsRAsFDIKuyBWpK0pU/UP7DWrxnCuU/rGXja4ncdGtuCHofG4Tkzj+IBY7MTED16isSkxLEFxDjiBAItRIKUxIoPCLgoYKy0xs5sDnDklXZ7EYo7/wDCQUF87DP8guVDBzbWUx6MY4IgRAUITMlOc7zwbznPf6G86e/44N5z1c5Rixi1Z0/BB4OKr6A2EfWLBZCjtEgt3HxK/x43iB3UCnDUhg/SbmWnDFjo36mYPRdQKB+l9CVGzcrDWEWDiolQ6Ibf0tMiBAIEeHA5o1V7vwB6iUm1Yg88qb6+/USkxj8yL8D4V22M1SY1fXxFYkVqjt/s6Q+WS8gvrBDrSFB8GBmSnr/z/Od+QY1UIbhqev+Mg+tK/wuhVGbQJiVYghFu5mpJ9w2f7MIIPdzIyQcNL6RGYFgKS/9+3zKTr1PVUdyIjUdy75p0DilSikMqGo+CcREY1aJM9B2X6YeI4K1+VfH110/GIuBrDgXm4hpSIgKvtx+grUvv1OjVIXndR1xD66hMNGEqr020QoEIxOQ2apyAAPHdpby4XGEmIaEqMA5+Pwb21Z2rzKYbXwt0XCmoBLqox0/+r3/82dOB2WiCVW7kamn/2+ceRN1vfMPJgnMPdiLL0DwRoRAsBxj2/Qw1r5cs6hdQr0Efvx+Df4KREpqs4CXWwzVnX9tpp5ABn6jO/9gk8DEFyBUR4RAsCVmM4V1r+wnsWFljaJ2ABUX11FdIDr0Gs5XO1caZkGbmWhC5SMIJrHLn9Xg3Hf+1UXAjSSBCYEiQiDYFqM7V+fglklig8wq7SrB+VhdIL79sjkdeg3ns78torpIdM7+FWk3XmN4x35dx8yQtAeCmaknsX6C4Z2/SgBtoAWSBCYESp2EQCl1DzAdyAR6e689rJR6EngQZynKx7XWH7ja7wDmAPWAl7XWhXXpgxBfmC2OXnHZQWKDmgJRdracb79sTmLDgYYi0SbzRhpcM54rleU0uKYB9ZKcd+D1kjIN283u8AOp6HnTra0CMvWY3flrB1IHSAgJdYoaUkplAg7gJbwWoVdKdca5TGVvoDWwHrjJ9bEvgYFAMbAT+LXW2jzMAYkaEqpiNoiahUX6Wj7RaCD1lWULxo5Wf0w6te3fbMA3Q5LAhNqIaPioUmoTVYXgSQCt9e9drz/AOXMAmK61Hmy0nRkiBEJtmJVO8F48pTpmphWz9gaN6lF5Rfs9sCfWTzCM3gnVcSXkU6gNq8NHrwP+7vW62NUG8G219lvD1AchjqgtLNLMnGSE0WAMTidsdSouO/hiy/Ean6nNpGPWbjRD6XdvR5//myDUlVqFQCm1HjA6457WWq80+5hBmwYSTNqNjpsL5AK0a9eutm4KgqmD1EwkAp0pmBHItr72X5upRwZ+IVzUKgRa6wFB7LcYaOv1ug1w3PXcrL36cecD88FpGgqiD4LgwUwkArHhB2rqCdSU5B70ZcAXIk24TEPvAq8rpZ7F6SzOAHbgnClkKKXaA8eAkcB9YeqDIPjElzkp7camdXb++jLpGO1fBECwirpGDY0AngeaA+eAPV6O4KeBcTiDt/O01n9ztf8C+BPO8NGFWutnajuOOIsFuxBIOKgM7ILVSNE5QRCEOMdfITBy3gqCIAhxhAiBIAhCnCNCIAiCEOeIEAiCIMQ5IgSCIAhxjgiBIAhCnBMV4aNKqe+AoxZ2oRkQ2DJXsY18H1WR76Mq8n1cxerv4nqtdfPaNooKIbAapdQuf2Jx4wX5Pqoi30dV5Pu4SrR8F2IaEgRBiHNECARBEOIcEQL/mG91B2yGfB9Vke+jKvJ9XCUqvgvxEQiCIMQ5MiMQBEGIc0QIfKCUukcp9YVSyqGU6lntvSeVUl8ppQ4qpQZb1UerUEpNV0odU0rtcf39wuo+RRql1B2u3/8rpVSB1f2xGqVUkVLqc9f5EHflgpVSC5VSp5RS+7zarlVKrVNKHXI9/tTKPpohQuCbfcC/AR97NyqlOuNcVKcLcAfwZ6VUvch3z3Jma617uP7et7ozkcT1e88F7gQ6A792nRfxTo7rfLB9yGQYWIRzPPCmAPhQa50BfOh6bTtECHygtT6gtT5o8NZwYKnWulxr/TXwFdA7sr0TLKY38JXW+ojW+jKwFOd5IcQpWuuPgbPVmocDi13PFwO/jGin/ESEIDiuA771el3saos3HlNK7XVNiW055Q0jcg7URANrlVK7lVK5VnfGJrTUWpcAuB5bWNwfQ8K1ZnHUoJRaDxitKfi01nql2ccM2mIu/MrXdwO8CPwO5//9O2AWzqVJ44W4OAcCpK/W+rhSqgWwTin1T9ddsmBz4l4ItNYDgvhYMdDW63Ub4HhoemQf/P1ulFJ/AVaFuTt2Iy7OgUDQWh93PZ5SSi3HaT6LdyE4qZRK01qXKKXSgFNWd8gIMQ0Fx7vASKVUA6VUeyAD2GFxnyKK66R2MwKnYz2e2AlkKKXaK6WScAYPvGtxnyxDKdVIKZXifg4MIv7OCSPeBca4no8BzKwMlhL3MwJfKKVGAM8DzYHVSqk9WuvBWusvlFJvAvuBCuBRrXWllX21gD8opXrgNIcUAQ9b253IorWuUEo9BnwA1AMWaq2/sLhbVtISWK6UAue48rrWeo21XYosSqk3gNuBZkqpYuC/gULgTaXUg8A3wD3W9dAcySwWBEGIc8Q0JAiCEOeIEAiCIMQ5IgSCIAhxjgiBIAhCnCNCIAiCEOeIEAiCIMQ5IgSCIAhxjgiBIAhCnPP/A/HL2sKgJb8qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_test = 500\n",
    "for x in [0, 5, 10]:\n",
    "    t = np.linspace(-x-1, x+1)\n",
    "    y_true = t * t - x * x\n",
    "    y_pred = deepIvEst.predict(t, np.full_like(t, x))\n",
    "    plt.scatter(t, y_true, label='true y, x={0}'.format(x))\n",
    "    plt.scatter(t, y_pred, label='pred y, x={0}'.format(x))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that despite the fact that the response surface varies with x, our model was able to fit the data reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at some real data from Angrist and Krueger's 1991 study [*Does Compulsory School Attendance Affect Schooling and Earnings?*](https://www.jstor.org/stable/2937954?seq=1#page_scan_tab_contents).  First we'll load the data (extracted from https://economics.mit.edu/faculty/angrist/data1/data/angkru1991) into a pandas dataframe and we'll apply the same processing used in the preparation of tables IV through VI in the paper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGEQ</th>\n",
       "      <th>v3</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>ENOCENT</th>\n",
       "      <th>ESOCENT</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>LWKLYWGE</th>\n",
       "      <th>MARRIED</th>\n",
       "      <th>...</th>\n",
       "      <th>QTR127</th>\n",
       "      <th>QTR227</th>\n",
       "      <th>QTR327</th>\n",
       "      <th>QTR128</th>\n",
       "      <th>QTR228</th>\n",
       "      <th>QTR328</th>\n",
       "      <th>QTR129</th>\n",
       "      <th>QTR229</th>\n",
       "      <th>QTR329</th>\n",
       "      <th>ONES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.955383</td>\n",
       "      <td>5.023558</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.993365</td>\n",
       "      <td>5.061540</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>41.50</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.310141</td>\n",
       "      <td>5.378315</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>46.25</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.110465</td>\n",
       "      <td>5.178639</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>46.00</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10.310601</td>\n",
       "      <td>6.378776</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.929236</td>\n",
       "      <td>4.997411</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>48.75</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9.205277</td>\n",
       "      <td>5.273452</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.993365</td>\n",
       "      <td>5.061540</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>47.50</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.758956</td>\n",
       "      <td>6.827130</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>44.75</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9.767066</td>\n",
       "      <td>5.835241</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>41.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>10.087870</td>\n",
       "      <td>6.156044</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43</td>\n",
       "      <td>43.75</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.336929</td>\n",
       "      <td>5.405103</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41</td>\n",
       "      <td>41.50</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.578415</td>\n",
       "      <td>5.646589</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46</td>\n",
       "      <td>46.25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.354557</td>\n",
       "      <td>5.358824</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>46.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.619100</td>\n",
       "      <td>5.687274</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41</td>\n",
       "      <td>41.50</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.263834</td>\n",
       "      <td>5.332008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46</td>\n",
       "      <td>46.50</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.831931</td>\n",
       "      <td>4.900105</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45</td>\n",
       "      <td>45.25</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.215279</td>\n",
       "      <td>5.283453</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47</td>\n",
       "      <td>47.75</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9.215279</td>\n",
       "      <td>5.283453</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>41</td>\n",
       "      <td>41.50</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.153717</td>\n",
       "      <td>5.272153</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.811893</td>\n",
       "      <td>5.880067</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>49</td>\n",
       "      <td>49.50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.306349</td>\n",
       "      <td>4.424785</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46</td>\n",
       "      <td>46.75</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9.215279</td>\n",
       "      <td>5.283453</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>43.75</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9.215279</td>\n",
       "      <td>5.283453</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43</td>\n",
       "      <td>43.75</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.244694</td>\n",
       "      <td>5.312868</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>40.75</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8.993365</td>\n",
       "      <td>5.220604</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47</td>\n",
       "      <td>47.25</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.860712</td>\n",
       "      <td>4.928886</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>48</td>\n",
       "      <td>48.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>9.905959</td>\n",
       "      <td>6.024395</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46</td>\n",
       "      <td>46.50</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10.087870</td>\n",
       "      <td>6.156044</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49</td>\n",
       "      <td>49.25</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10.001045</td>\n",
       "      <td>6.069220</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063604</th>\n",
       "      <td>39</td>\n",
       "      <td>39.25</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.595942</td>\n",
       "      <td>5.644699</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063605</th>\n",
       "      <td>33</td>\n",
       "      <td>33.00</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9.210840</td>\n",
       "      <td>5.298817</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063606</th>\n",
       "      <td>35</td>\n",
       "      <td>35.50</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.309119</td>\n",
       "      <td>6.357876</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063607</th>\n",
       "      <td>30</td>\n",
       "      <td>30.75</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.798405</td>\n",
       "      <td>5.847161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063608</th>\n",
       "      <td>32</td>\n",
       "      <td>32.75</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>9.306105</td>\n",
       "      <td>5.354861</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063609</th>\n",
       "      <td>31</td>\n",
       "      <td>31.00</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9.473089</td>\n",
       "      <td>5.521845</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063610</th>\n",
       "      <td>38</td>\n",
       "      <td>38.50</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.166044</td>\n",
       "      <td>6.214800</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063611</th>\n",
       "      <td>30</td>\n",
       "      <td>30.25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.631414</td>\n",
       "      <td>4.680171</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063612</th>\n",
       "      <td>30</td>\n",
       "      <td>30.50</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9.210840</td>\n",
       "      <td>5.259596</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063613</th>\n",
       "      <td>32</td>\n",
       "      <td>32.00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.616138</td>\n",
       "      <td>5.664895</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063614</th>\n",
       "      <td>31</td>\n",
       "      <td>31.00</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9.903737</td>\n",
       "      <td>5.952494</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063615</th>\n",
       "      <td>38</td>\n",
       "      <td>38.75</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.661098</td>\n",
       "      <td>5.789896</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063616</th>\n",
       "      <td>31</td>\n",
       "      <td>31.00</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.518192</td>\n",
       "      <td>6.726433</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063617</th>\n",
       "      <td>31</td>\n",
       "      <td>31.25</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8.818038</td>\n",
       "      <td>4.866795</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063618</th>\n",
       "      <td>32</td>\n",
       "      <td>32.00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.741262</td>\n",
       "      <td>5.790019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063619</th>\n",
       "      <td>32</td>\n",
       "      <td>32.00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.903737</td>\n",
       "      <td>5.952494</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063620</th>\n",
       "      <td>39</td>\n",
       "      <td>39.25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.558543</td>\n",
       "      <td>6.607300</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063621</th>\n",
       "      <td>33</td>\n",
       "      <td>33.50</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.976041</td>\n",
       "      <td>6.024797</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063622</th>\n",
       "      <td>36</td>\n",
       "      <td>36.25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.852457</td>\n",
       "      <td>5.901214</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063623</th>\n",
       "      <td>31</td>\n",
       "      <td>31.75</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.304108</td>\n",
       "      <td>6.352864</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063624</th>\n",
       "      <td>31</td>\n",
       "      <td>31.50</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.107754</td>\n",
       "      <td>5.156510</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063625</th>\n",
       "      <td>31</td>\n",
       "      <td>31.50</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9.130755</td>\n",
       "      <td>5.179512</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063626</th>\n",
       "      <td>35</td>\n",
       "      <td>35.50</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.306105</td>\n",
       "      <td>5.354861</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063627</th>\n",
       "      <td>39</td>\n",
       "      <td>39.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.225244</td>\n",
       "      <td>7.274000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063628</th>\n",
       "      <td>36</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.287765</td>\n",
       "      <td>5.336521</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063629</th>\n",
       "      <td>30</td>\n",
       "      <td>30.50</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9.432283</td>\n",
       "      <td>5.481040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063630</th>\n",
       "      <td>34</td>\n",
       "      <td>34.25</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.616138</td>\n",
       "      <td>5.664895</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063631</th>\n",
       "      <td>33</td>\n",
       "      <td>33.50</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9.852457</td>\n",
       "      <td>6.163578</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063632</th>\n",
       "      <td>35</td>\n",
       "      <td>35.00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.473089</td>\n",
       "      <td>5.521845</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063633</th>\n",
       "      <td>32</td>\n",
       "      <td>32.50</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>10.166044</td>\n",
       "      <td>6.294843</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063634 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AGE   AGEQ  v3  EDUC  ENOCENT  ESOCENT  v7         v8  LWKLYWGE  \\\n",
       "0         40  40.50   1    11        0        0  13   8.955383  5.023558   \n",
       "1         41  41.00   1    12        0        0  14   8.993365  5.061540   \n",
       "2         41  41.50   1    12        0        0  14   9.310141  5.378315   \n",
       "3         46  46.25   1    12        0        0  14   9.110465  5.178639   \n",
       "4         46  46.00   1    16        0        0  18  10.310601  6.378776   \n",
       "5         47  47.00   1    12        0        0  14   8.929236  4.997411   \n",
       "6         48  48.75   1    14        0        0  16   9.205277  5.273452   \n",
       "7         41  41.75   2     9        0        0  12   8.993365  5.061540   \n",
       "8         47  47.50   1    12        0        0  14  10.758956  6.827130   \n",
       "9         44  44.75   2    17        0        0  20   9.767066  5.835241   \n",
       "10        41  41.75   1    17        0        0  19  10.087870  6.156044   \n",
       "11        43  43.75   1    16        0        0  18   9.336929  5.405103   \n",
       "12        41  41.50   2     8        0        0  11   9.578415  5.646589   \n",
       "13        46  46.25   2    10        0        0  13   8.354557  5.358824   \n",
       "14        46  46.50   1     9        0        0  11   9.619100  5.687274   \n",
       "15        41  41.50   1    12        0        0  14   9.263834  5.332008   \n",
       "16        46  46.50   1    11        0        0  13   8.831931  4.900105   \n",
       "17        45  45.25   1    12        0        0  14   9.215279  5.283453   \n",
       "18        47  47.75   1    14        0        0  16   9.215279  5.283453   \n",
       "19        41  41.50   2     9        0        0  12   9.153717  5.272153   \n",
       "20        41  41.00   1    12        0        0  14   9.811893  5.880067   \n",
       "21        49  49.50   2    10        0        0  13   8.306349  4.424785   \n",
       "22        46  46.75   1    13        0        0  15   9.215279  5.283453   \n",
       "23        43  43.75   1     8        0        0  10   9.215279  5.283453   \n",
       "24        43  43.75   1     9        0        0  11   9.244694  5.312868   \n",
       "25        40  40.75   1    16        0        0  18   8.993365  5.220604   \n",
       "26        47  47.25   1    12        0        0  14   8.860712  4.928886   \n",
       "27        48  48.75   1    17        0        0  19   9.905959  6.024395   \n",
       "28        46  46.50   1    16        0        0  18  10.087870  6.156044   \n",
       "29        49  49.25   1    16        0        0  18  10.001045  6.069220   \n",
       "...      ...    ...  ..   ...      ...      ...  ..        ...       ...   \n",
       "1063604   39  39.25   2    11        0        0  13   9.595942  5.644699   \n",
       "1063605   33  33.00   2    15        0        0  17   9.210840  5.298817   \n",
       "1063606   35  35.50   2    12        0        0  14  10.309119  6.357876   \n",
       "1063607   30  30.75   2    16        0        0  18   9.798405  5.847161   \n",
       "1063608   32  32.75   2    17        0        0  19   9.306105  5.354861   \n",
       "1063609   31  31.00   2    13        0        0  15   9.473089  5.521845   \n",
       "1063610   38  38.50   2    18        0        0  20  10.166044  6.214800   \n",
       "1063611   30  30.25   2    12        0        0  14   8.631414  4.680171   \n",
       "1063612   30  30.50   2    13        0        0  15   9.210840  5.259596   \n",
       "1063613   32  32.00   2    12        0        0  14   9.616138  5.664895   \n",
       "1063614   31  31.00   2    14        0        0  16   9.903737  5.952494   \n",
       "1063615   38  38.75   2    12        0        0  14   9.661098  5.789896   \n",
       "1063616   31  31.00   2    11        0        0  13   8.518192  6.726433   \n",
       "1063617   31  31.25   1    12        0        0  15   8.818038  4.866795   \n",
       "1063618   32  32.00   2    12        0        0  14   9.741262  5.790019   \n",
       "1063619   32  32.00   2    12        0        0  14   9.903737  5.952494   \n",
       "1063620   39  39.25   2    12        0        0  14  10.558543  6.607300   \n",
       "1063621   33  33.50   2    16        0        0  18   9.976041  6.024797   \n",
       "1063622   36  36.25   2    12        0        0  14   9.852457  5.901214   \n",
       "1063623   31  31.75   2    12        0        0  14  10.304108  6.352864   \n",
       "1063624   31  31.50   2    12        0        0  14   9.107754  5.156510   \n",
       "1063625   31  31.50   2    20        0        0  22   9.130755  5.179512   \n",
       "1063626   35  35.50   2    12        0        0  14   9.306105  5.354861   \n",
       "1063627   39  39.50   3     0        0        0   3  11.225244  7.274000   \n",
       "1063628   36  36.00   2    12        0        0  14   9.287765  5.336521   \n",
       "1063629   30  30.50   1    12        0        0  15   9.432283  5.481040   \n",
       "1063630   34  34.25   2    16        0        0  18   9.616138  5.664895   \n",
       "1063631   33  33.50   2    18        0        0  20   9.852457  6.163578   \n",
       "1063632   35  35.00   2    12        0        0  14   9.473089  5.521845   \n",
       "1063633   32  32.50   2    13        0        0  15  10.166044  6.294843   \n",
       "\n",
       "         MARRIED  ...   QTR127  QTR227  QTR327  QTR128  QTR228  QTR328  \\\n",
       "0              1  ...    False   False   False   False   False   False   \n",
       "1              1  ...    False   False   False   False   False   False   \n",
       "2              1  ...    False   False   False   False   False   False   \n",
       "3              1  ...    False   False   False   False   False   False   \n",
       "4              1  ...    False   False   False   False   False   False   \n",
       "5              0  ...    False   False   False   False   False   False   \n",
       "6              1  ...    False   False   False   False   False   False   \n",
       "7              1  ...    False   False   False   False   False    True   \n",
       "8              1  ...    False   False   False   False   False   False   \n",
       "9              1  ...    False   False   False   False   False   False   \n",
       "10             1  ...    False   False   False   False   False    True   \n",
       "11             0  ...    False   False   False   False   False   False   \n",
       "12             1  ...    False   False   False   False   False   False   \n",
       "13             1  ...    False   False   False   False   False   False   \n",
       "14             1  ...    False   False   False   False   False   False   \n",
       "15             0  ...    False   False   False   False   False   False   \n",
       "16             1  ...    False   False   False   False   False   False   \n",
       "17             1  ...    False   False   False   False   False   False   \n",
       "18             1  ...    False   False   False   False   False   False   \n",
       "19             1  ...    False   False   False   False   False   False   \n",
       "20             1  ...    False   False   False   False   False   False   \n",
       "21             1  ...    False   False   False   False   False   False   \n",
       "22             0  ...    False   False   False   False   False   False   \n",
       "23             1  ...    False   False   False   False   False   False   \n",
       "24             1  ...    False   False   False   False   False   False   \n",
       "25             1  ...    False   False   False   False   False   False   \n",
       "26             1  ...    False   False   False   False   False   False   \n",
       "27             0  ...    False   False   False   False   False   False   \n",
       "28             1  ...    False   False   False   False   False   False   \n",
       "29             1  ...    False   False   False   False   False   False   \n",
       "...          ...  ...      ...     ...     ...     ...     ...     ...   \n",
       "1063604        1  ...    False   False   False   False   False   False   \n",
       "1063605        1  ...    False    True   False   False   False   False   \n",
       "1063606        1  ...    False   False   False   False   False   False   \n",
       "1063607        1  ...    False   False   False   False   False   False   \n",
       "1063608        1  ...    False   False    True   False   False   False   \n",
       "1063609        1  ...    False   False   False   False   False   False   \n",
       "1063610        1  ...    False   False   False   False   False   False   \n",
       "1063611        1  ...    False   False   False   False   False   False   \n",
       "1063612        1  ...    False   False   False   False   False   False   \n",
       "1063613        1  ...    False   False   False   False    True   False   \n",
       "1063614        1  ...    False   False   False   False   False   False   \n",
       "1063615        0  ...    False   False   False   False   False   False   \n",
       "1063616        0  ...    False   False   False   False   False   False   \n",
       "1063617        1  ...    False   False   False   False   False   False   \n",
       "1063618        1  ...    False   False   False   False    True   False   \n",
       "1063619        0  ...    False   False   False   False    True   False   \n",
       "1063620        1  ...    False   False   False   False   False   False   \n",
       "1063621        1  ...    False   False   False   False   False   False   \n",
       "1063622        1  ...    False   False   False   False   False   False   \n",
       "1063623        1  ...    False   False   False   False   False    True   \n",
       "1063624        0  ...    False   False   False   False   False   False   \n",
       "1063625        1  ...    False   False   False   False   False   False   \n",
       "1063626        0  ...    False   False   False   False   False   False   \n",
       "1063627        1  ...    False   False   False   False   False   False   \n",
       "1063628        1  ...    False   False   False   False   False   False   \n",
       "1063629        0  ...    False   False   False   False   False   False   \n",
       "1063630        1  ...    False   False   False   False   False   False   \n",
       "1063631        1  ...    False   False   False   False   False   False   \n",
       "1063632        1  ...    False   False   False   False   False   False   \n",
       "1063633        0  ...    False   False   False   False   False   False   \n",
       "\n",
       "         QTR129  QTR229  QTR329  ONES  \n",
       "0         False   False   False     1  \n",
       "1         False    True   False     1  \n",
       "2         False   False   False     1  \n",
       "3         False   False   False     1  \n",
       "4         False   False   False     1  \n",
       "5         False   False   False     1  \n",
       "6         False   False   False     1  \n",
       "7         False   False   False     1  \n",
       "8         False   False   False     1  \n",
       "9         False   False   False     1  \n",
       "10        False   False   False     1  \n",
       "11        False   False   False     1  \n",
       "12        False   False   False     1  \n",
       "13        False   False   False     1  \n",
       "14        False   False   False     1  \n",
       "15        False   False   False     1  \n",
       "16        False   False   False     1  \n",
       "17        False   False   False     1  \n",
       "18        False   False   False     1  \n",
       "19        False   False   False     1  \n",
       "20        False    True   False     1  \n",
       "21        False   False   False     1  \n",
       "22        False   False   False     1  \n",
       "23        False   False   False     1  \n",
       "24        False   False   False     1  \n",
       "25        False   False    True     1  \n",
       "26        False   False   False     1  \n",
       "27        False   False   False     1  \n",
       "28        False   False   False     1  \n",
       "29        False   False   False     1  \n",
       "...         ...     ...     ...   ...  \n",
       "1063604   False   False   False     1  \n",
       "1063605   False   False   False     1  \n",
       "1063606   False   False   False     1  \n",
       "1063607   False   False    True     1  \n",
       "1063608   False   False   False     1  \n",
       "1063609   False    True   False     1  \n",
       "1063610   False   False   False     1  \n",
       "1063611   False   False   False     1  \n",
       "1063612   False   False   False     1  \n",
       "1063613   False   False   False     1  \n",
       "1063614   False    True   False     1  \n",
       "1063615   False   False   False     1  \n",
       "1063616   False    True   False     1  \n",
       "1063617   False   False   False     1  \n",
       "1063618   False   False   False     1  \n",
       "1063619   False   False   False     1  \n",
       "1063620   False   False   False     1  \n",
       "1063621   False   False   False     1  \n",
       "1063622   False   False   False     1  \n",
       "1063623   False   False   False     1  \n",
       "1063624   False   False   False     1  \n",
       "1063625   False   False   False     1  \n",
       "1063626   False   False   False     1  \n",
       "1063627   False   False   False     1  \n",
       "1063628   False   False   False     1  \n",
       "1063629   False   False   False     1  \n",
       "1063630   False   False   False     1  \n",
       "1063631   False   False   False     1  \n",
       "1063632   False   False   False     1  \n",
       "1063633   False   False   False     1  \n",
       "\n",
       "[1063634 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_stata('../econml/data/NEW7080.dta')\n",
    "df.rename(columns = \n",
    "              {\"v1\":\"AGE\", \n",
    "               \"v2\":\"AGEQ\", \n",
    "               \"v4\":\"EDUC\", \n",
    "               \"v5\":\"ENOCENT\", \n",
    "               \"v6\":\"ESOCENT\", \n",
    "               \"v9\":\"LWKLYWGE\", \n",
    "               \"v10\":\"MARRIED\", \n",
    "               \"v11\":\"MIDATL\", \n",
    "               \"v12\":\"MT\", \n",
    "               \"v13\":\"NEWENG\", \n",
    "               \"v16\":\"CENSUS\", \n",
    "               \"v18\":\"QOB\", \n",
    "               \"v19\":\"RACE\", \n",
    "               \"v20\":\"SMSA\", \n",
    "               \"v21\":\"SOATL\", \n",
    "               \"v24\":\"WNOCENT\", \n",
    "               \"v25\":\"WSOCENT\", \n",
    "               \"v27\":\"YOB\"},\n",
    "         inplace = True)\n",
    "\n",
    "df[\"COHORT\"] = \"20.29\"\n",
    "df.loc[(df[\"YOB\"] <= 39) & (df[\"YOB\"] >= 30), \"COHORT\"] = \"30.39\"\n",
    "df.loc[(df[\"YOB\"] <= 49) & (df[\"YOB\"] >= 40), \"COHORT\"] = \"40.49\"\n",
    "\n",
    "df.loc[df[\"CENSUS\"] == 80, \"AGEQ\"] = df[df[\"CENSUS\"] == 80][\"AGEQ\"] - 1900 \n",
    "df[\"AGEQSQ\"] = df[\"AGEQ\"] ** 2\n",
    "\n",
    "for i in range(10): df[\"YR2\" + str(i)] = df[\"YOB\"] % 10 == i\n",
    "for j in range(4): df[\"QTR\" + str(j+1)] = df[\"QOB\"] == j\n",
    "for i in range(10):\n",
    "    for j in range(3):\n",
    "        df[\"QTR\" + str(j+1) + \"2\" + str(i)] = df[\"QTR\" + str(j+1)] & df[\"YR2\" + str(i)]\n",
    "\n",
    "df[\"ONES\"] = 1\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll reproduce the results from Angrist and Krueger's table V using 2-stage least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[0.09682285, 0.06297094, 0.05301453, 0.04352032, 0.03944406,\n",
       "          0.03511468, 0.02163817, 0.02118264, 0.01451108, 0.01227352,\n",
       "          4.63374403]]),\n",
       "  array([[0.07108105, 0.04816363, 0.04177617, 0.03332525, 0.03058047,\n",
       "          0.02716437, 0.01526895, 0.01638286, 0.01145151, 0.01127317,\n",
       "          4.96918464]])),\n",
       " (array([[ 8.34893655e-02,  8.78181407e-02,  8.32868271e-02,\n",
       "           7.61334947e-02,  7.26698845e-02,  6.70242649e-02,\n",
       "           5.07400718e-02,  4.57444183e-02,  3.27945616e-02,\n",
       "           2.25803563e-02, -8.45689616e-02,  8.97074202e-04,\n",
       "           6.76246711e+00]]),\n",
       "  array([[ 7.10736632e-02,  1.03340351e-01,  9.71334422e-02,\n",
       "           8.72853465e-02,  8.15684023e-02,  7.35620837e-02,\n",
       "           5.55608302e-02,  4.89979131e-02,  3.47328318e-02,\n",
       "           2.37346805e-02, -7.71897458e-02,  7.87435543e-04,\n",
       "           6.80540754e+00]])),\n",
       " (array([[ 0.08755452,  0.04563263,  0.03799053,  0.03253513,  0.03101963,\n",
       "           0.02731856,  0.01571405,  0.01530334,  0.01094546,  0.01097097,\n",
       "          -0.22118437,  0.24235316, -0.15089901, -0.09959412, -0.0358199 ,\n",
       "           0.04163923, -0.0900411 , -0.11261465, -0.12390425, -0.08012339,\n",
       "          -0.08635691,  4.6459062 ]]),\n",
       "  array([[ 0.06324573,  0.03063636,  0.02659109,  0.02217463,  0.02229135,\n",
       "           0.01948329,  0.00981785,  0.01025016,  0.00760091,  0.00846834,\n",
       "          -0.2574833 ,  0.24786744, -0.17630067, -0.11338389, -0.05276539,\n",
       "           0.01597112, -0.10777252, -0.13930919, -0.16444937, -0.10317845,\n",
       "          -0.09209341,  4.98579201]])),\n",
       " (array([[ 5.81706106e-02,  9.44733745e-02,  8.95395568e-02,\n",
       "           8.23312110e-02,  7.82621639e-02,  6.95900431e-02,\n",
       "           5.29023222e-02,  4.47031543e-02,  3.19881667e-02,\n",
       "           2.15224606e-02, -2.65430020e-01,  2.49020210e-01,\n",
       "          -1.81604501e-01, -1.16285411e-01, -5.62056125e-02,\n",
       "           1.05786820e-02, -1.11523998e-01, -1.44906311e-01,\n",
       "          -1.72928981e-01, -1.08094110e-01, -9.33158505e-02,\n",
       "          -7.31168131e-02,  7.27829808e-04,  6.82580312e+00]]),\n",
       "  array([[ 6.32378016e-02,  8.88003467e-02,  8.44662180e-02,\n",
       "           7.82174992e-02,  7.49617408e-02,  6.71940603e-02,\n",
       "           5.10922565e-02,  4.35515769e-02,  3.13043394e-02,\n",
       "           2.11243421e-02, -2.57453377e-01,  2.47878492e-01,\n",
       "          -1.76290344e-01, -1.13357094e-01, -5.27515447e-02,\n",
       "           1.59562821e-02, -1.07798758e-01, -1.39342433e-01,\n",
       "          -1.64455393e-01, -1.03279552e-01, -9.21064418e-02,\n",
       "          -7.59682928e-02,  7.70224662e-04,  6.80080975e+00]]))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cohort = df[df[\"COHORT\"] == \"30.39\"]\n",
    "ols_model = LinearRegression(fit_intercept=False)\n",
    "y_vars = [\"LWKLYWGE\"]\n",
    "Y_vars = [\"EDUC\"]\n",
    "X2_vars = [\"QTR\" + str(j+1) + \"2\" + str(i) for i in range(10) for j in range(3)] + [\"YR2\" + str(i) for i in range(9)] \n",
    "demo_vars = [\"RACE\", \"MARRIED\", \"SMSA\", \"NEWENG\", \"MIDATL\", \"ENOCENT\", \"WNOCENT\", \"SOATL\", \"ESOCENT\", \"WSOCENT\", \"MT\"]\n",
    "age_vars = [\"AGEQ\", \"AGEQSQ\"]\n",
    "results = []\n",
    "for include_demo in [False, True]:\n",
    "    for include_age in [False, True]:\n",
    "        X1_vars = [\"YR2\" + str(i) for i in range(9)] \n",
    "        if include_demo:\n",
    "            X1_vars = X1_vars + demo_vars\n",
    "        if include_age:\n",
    "            X1_vars = X1_vars + age_vars\n",
    "        X1_vars.append(\"ONES\")\n",
    "        X_vars = Y_vars + X1_vars\n",
    "        Z_vars = X1_vars + X2_vars\n",
    "        X_pred = ols_model.fit(cohort[Z_vars], cohort[X_vars]).predict(cohort[Z_vars])\n",
    "        beta_iv = ols_model.fit(X_pred, cohort[y_vars]).coef_\n",
    "        beta_ols = ols_model.fit(cohort[X_vars],cohort[y_vars]).coef_\n",
    "        results.append((beta_iv, beta_ols))\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 296558 samples, validate on 32951 samples\n",
      "Epoch 1/30\n",
      "192512/296558 [==================>...........] - ETA: 1:11 - loss: 1.8746- ET"
     ]
    }
   ],
   "source": [
    "# Z=[QOB, YOB], X=[]\n",
    "treatment_model = keras.Sequential([keras.layers.Dense(512, activation='relu', input_shape=(2,)),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(512, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(512, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(256, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(64, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(32, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17)])\n",
    "\n",
    "response_model = keras.Sequential([keras.layers.Dense(1000, activation='relu', input_shape=(1,)),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(1000, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(1)])\n",
    "\n",
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.1,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}\n",
    "\n",
    "adam = keras.optimizers.Adam(clipnorm=1)\n",
    "\n",
    "deepIvEst = DeepIVEstimator(n_components = 5, # number of gaussians in our mixture density network\n",
    "                            m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "                            h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "                            n_samples = 2, # number of samples to use to estimate the response\n",
    "                            use_upper_bound_loss = False, # whether to use an approximation to the true loss\n",
    "                            n_gradient_samples = 2, # number of samples to use in second estimate of the response (to make loss estimate unbiased)\n",
    "                            optimizer=adam, # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "                            first_stage_options=keras_fit_options, # options for training treatment model\n",
    "                            second_stage_options=keras_fit_options) # options for training response model\n",
    "\n",
    "cohort = cohort.sample(frac=1)\n",
    "\n",
    "deepIvEst.fit(Y=cohort[[\"LWKLYWGE\"]],T=cohort[[\"EDUC\"]],X=cohort[[]],Z=cohort[[\"QOB\",\"YOB\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(0, 20, 50)\n",
    "y_pred = deepIvEst.predict(t, np.zeros((len(t),0)))\n",
    "plt.scatter(t, y_pred, label='pred y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42259073]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepIvEst.predict([[5.1]],[[]])-deepIvEst.predict([[4.1]],[[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_134 (InputLayer)       (None, 4, 3)              0         \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, 4, 5)              0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 4, 5)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [32,3] vs. shape[1] = [8,2]\n\t [[{{node time_distributed_62/concatenate_159/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](time_distributed_62/Reshape, _arg_input_133_0_0, time_distributed_62/concatenate_159/concat/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-99182f085f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0md_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda4.2.0\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [32,3] vs. shape[1] = [8,2]\n\t [[{{node time_distributed_62/concatenate_159/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](time_distributed_62/Reshape, _arg_input_133_0_0, time_distributed_62/concatenate_159/concat/axis)]]"
     ]
    }
   ],
   "source": [
    "import keras.layers as L\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "n_s = 4\n",
    "d_x = 2\n",
    "d_t = 3\n",
    "d_y = 5\n",
    "b = 8\n",
    "x = L.Input((d_x,))\n",
    "ps = L.Input((n_s,d_t))\n",
    "\n",
    "td = L.TimeDistributed(L.Lambda(lambda q: L.Concatenate()([q,x])))(ps)\n",
    "\n",
    "m = keras.Model([x,ps], td)\n",
    "\n",
    "m.compile('adam','mse')\n",
    "m.summary()\n",
    "print(m.output_shape)\n",
    "m.fit([np.random.normal(size=(b, d_x)), np.random.normal(size=(b, n_s, d_t))], np.random.normal(size=(b, n_s, d_t+d_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
